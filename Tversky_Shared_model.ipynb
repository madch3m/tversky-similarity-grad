{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn2wSt1j3X/IFviFbkQ6Ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e448436c3274497a181fd890a3e47b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d0a4b5caf284edf9514257058addf6d",
              "IPY_MODEL_e2d5e508748d4eae9d9ef0c3792cecd2",
              "IPY_MODEL_fe830cae18824d27b90009868041d16f"
            ],
            "layout": "IPY_MODEL_b493c7969c24472b865590a06e0b8275"
          }
        },
        "7d0a4b5caf284edf9514257058addf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a85903a146467e885d9d35d2be05ac",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6c6a9923e64120b22a2e5ffb2c6ec4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e2d5e508748d4eae9d9ef0c3792cecd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f428aad3f75a485c9ba5d7984dfbc125",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bf947d16724e25abad8d5ff91149c8",
            "value": 26
          }
        },
        "fe830cae18824d27b90009868041d16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8913943aae6c40a580982d69de80709c",
            "placeholder": "​",
            "style": "IPY_MODEL_cab4ede138b543aebe46d180a10ffa85",
            "value": " 26.0/26.0 [00:00&lt;00:00, 740B/s]"
          }
        },
        "b493c7969c24472b865590a06e0b8275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a85903a146467e885d9d35d2be05ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6c6a9923e64120b22a2e5ffb2c6ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f428aad3f75a485c9ba5d7984dfbc125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bf947d16724e25abad8d5ff91149c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8913943aae6c40a580982d69de80709c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab4ede138b543aebe46d180a10ffa85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02ee4e81b7843fbbdee32f1a758c029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ba4a70e9f7744d1be73fc6942122713",
              "IPY_MODEL_c18326fc6d0b408aa076571be8730782",
              "IPY_MODEL_f8dce00a17c542b78b4a8d1d3f05dcbf"
            ],
            "layout": "IPY_MODEL_474f11a1c05b4f6b99ee6042cfaa7598"
          }
        },
        "8ba4a70e9f7744d1be73fc6942122713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97016b15e051446d8092e8f7efa12988",
            "placeholder": "​",
            "style": "IPY_MODEL_39f9ef6b70fa40e58d460e462ae6d88a",
            "value": "vocab.json: 100%"
          }
        },
        "c18326fc6d0b408aa076571be8730782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45545862acf4d56924d6f9d17b8110e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15f01687d28c44ad96338bed3b45e873",
            "value": 1042301
          }
        },
        "f8dce00a17c542b78b4a8d1d3f05dcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_976490aeb1324ed1880f49c7230fb69e",
            "placeholder": "​",
            "style": "IPY_MODEL_dc0023fdf4cf43e9a802d4250a7ad6d6",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.45MB/s]"
          }
        },
        "474f11a1c05b4f6b99ee6042cfaa7598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97016b15e051446d8092e8f7efa12988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f9ef6b70fa40e58d460e462ae6d88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f45545862acf4d56924d6f9d17b8110e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f01687d28c44ad96338bed3b45e873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "976490aeb1324ed1880f49c7230fb69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0023fdf4cf43e9a802d4250a7ad6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae8e6a3d4a44ff8a47ec7184c200c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bad0fa313a94414f92c012ad7685e358",
              "IPY_MODEL_f614d57c779a4235879a363e8e357352",
              "IPY_MODEL_2f81a08b211144ceac3f4902e623a36b"
            ],
            "layout": "IPY_MODEL_c89c4caaf9a24788b961186a292a84d6"
          }
        },
        "bad0fa313a94414f92c012ad7685e358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be92bfa7074240f1b2ab2687f32aa175",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4c150e85384375a6da1372d3428117",
            "value": "merges.txt: 100%"
          }
        },
        "f614d57c779a4235879a363e8e357352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79773233ce484defb53056f2b97bc2f8",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b495d5611a3e43589dab5a8966e3505f",
            "value": 456318
          }
        },
        "2f81a08b211144ceac3f4902e623a36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8615e7beaa4240caa6ba23d3d96698bd",
            "placeholder": "​",
            "style": "IPY_MODEL_0f7e9429853040d6b61edcfe48e430ed",
            "value": " 456k/456k [00:00&lt;00:00, 3.85MB/s]"
          }
        },
        "c89c4caaf9a24788b961186a292a84d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be92bfa7074240f1b2ab2687f32aa175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4c150e85384375a6da1372d3428117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79773233ce484defb53056f2b97bc2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b495d5611a3e43589dab5a8966e3505f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8615e7beaa4240caa6ba23d3d96698bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7e9429853040d6b61edcfe48e430ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f326007577b4bfab90e8843613561f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90198dd3098b49ffbfb27d2415554b26",
              "IPY_MODEL_127b395b24164d10bc9406341ab1bcb5",
              "IPY_MODEL_6668151623de49b68047680a2669b91e"
            ],
            "layout": "IPY_MODEL_d7b6d815e3364d7ba8011fcf4c15cbc4"
          }
        },
        "90198dd3098b49ffbfb27d2415554b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb52da00a4ed486d83033fba8b6b9389",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea4b9a29429439581d378cb94596a90",
            "value": "tokenizer.json: 100%"
          }
        },
        "127b395b24164d10bc9406341ab1bcb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134cf8d81538442b9e2eee97215bab3b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43cfcc944a3f4820b3466df92319df2d",
            "value": 1355256
          }
        },
        "6668151623de49b68047680a2669b91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f262a221c21945f7801443cddfb5bf36",
            "placeholder": "​",
            "style": "IPY_MODEL_b7dc63a5378e446bb5999dc8de838c90",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.31MB/s]"
          }
        },
        "d7b6d815e3364d7ba8011fcf4c15cbc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb52da00a4ed486d83033fba8b6b9389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea4b9a29429439581d378cb94596a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "134cf8d81538442b9e2eee97215bab3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43cfcc944a3f4820b3466df92319df2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f262a221c21945f7801443cddfb5bf36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7dc63a5378e446bb5999dc8de838c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "834bf635eb76462db4a1a54c8b7e556a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41f0318faf0b403a9b1a5016ba5d149f",
              "IPY_MODEL_5ad2062e0e47468ea4146975ad8be198",
              "IPY_MODEL_cf92d3dbbc674ec9bcf6c59a8af19705"
            ],
            "layout": "IPY_MODEL_91ba0adf5d7b42e9b4f1fbd4a036ea86"
          }
        },
        "41f0318faf0b403a9b1a5016ba5d149f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba43c6e9ee9744b198146fa96e72ca6f",
            "placeholder": "​",
            "style": "IPY_MODEL_8654349834214312be1ea0d9cd4e01a5",
            "value": "config.json: 100%"
          }
        },
        "5ad2062e0e47468ea4146975ad8be198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964682f106524e749d7549eb99c13da9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a118747f41e74097887f54059f030f07",
            "value": 665
          }
        },
        "cf92d3dbbc674ec9bcf6c59a8af19705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb27128a29784a208c723ca8e925cb2b",
            "placeholder": "​",
            "style": "IPY_MODEL_0d78592d0ed64a978dc820fc347bdda5",
            "value": " 665/665 [00:00&lt;00:00, 6.25kB/s]"
          }
        },
        "91ba0adf5d7b42e9b4f1fbd4a036ea86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba43c6e9ee9744b198146fa96e72ca6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8654349834214312be1ea0d9cd4e01a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "964682f106524e749d7549eb99c13da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a118747f41e74097887f54059f030f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb27128a29784a208c723ca8e925cb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d78592d0ed64a978dc820fc347bdda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madch3m/tversky-similarity-grad/blob/visualization/Tversky_Shared_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnSrvL8b7109"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tversky Layer GPT Implementation"
      ],
      "metadata": {
        "id": "JzsKh98872xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm6QKxPu8UeJ",
        "outputId": "7411bb93-321d-42c1-a8c3-ac7d25f9aad5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
        "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
        "class TverskyProjectionLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, alpha=0.5, beta=0.5,gamma=1.0):\n",
        "        super(TverskyProjectionLayer, self).__init__()\n",
        "        self.features = nn.Parameter(torch.randn(out_features,in_features))\n",
        "        self.prototypes = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.beta = nn.Parameter(torch.randn(in_features, in_features))\n",
        "        self.gamma = nn.Parameter(torch.tensor(alpha))\n",
        "\n",
        "        nn.init.xavier_uniform_(self.prototypes)\n",
        "        nn.init.xavier_uniform_(self.features)\n",
        "\n",
        "    def commonality(self, x, prototype):\n",
        "        x_feature_activations = torch.matmul(x, self.features)\n",
        "        x_features = F.relu(x_feature_activations)\n",
        "        prototype_feature_activations = torch.matmul(prototype, self.features)\n",
        "        prototype_features = F.relu(prototype_feature_activations)\n",
        "\n",
        "        common_features = torch.sum(torch.min(x_features,prototype_features))\n",
        "\n",
        "        return common, x_features, prototype_features\n",
        "\n",
        "    def distinct_features(self, features_alpha ,features_beta):\n",
        "        distinctive = torch.sum(F.relu(features_alpha - features_beta),dim=-1)\n",
        "        return distinctive\n",
        "\n",
        "    def tversky_similarity(self, x, prototype):\n",
        "        common, x_features, prototype_features = self.commonality(x,prototype)\n",
        "        distinctive_x = self.distinctive(x_features, prototype_features)\n",
        "        distinctive_prototype = self.distinctive(prototype_features,x_features)\n",
        "\n",
        "        numerator = self.gamma * common\n",
        "        denominator = (self.gamma * common + torch.abs(self.alpha) * distinctive_x + torch.abs(self.beta) * distinctive_prototype + 1e-8)\n",
        "        similarity = numerator / denominator\n",
        "\n",
        "        return similarity\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_shape = x.shape\n",
        "\n",
        "        if len(x.shape) == 3:\n",
        "            batch_size, seq_len, in_features = x.shape\n",
        "            x = x.view(-1, in_features)\n",
        "\n",
        "        else:\n",
        "            batch_size = None\n",
        "            seq_len = None\n",
        "\n",
        "        similarities = []\n",
        "\n",
        "        for i in range(self.prototypes.size(0)):\n",
        "            similarity = self.tversky_similarity(x,self.prototypes[i])\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        output = torch.stack(similarities, dim=0)\n",
        "\n",
        "        if batch_size is not None and seq_len is not None:\n",
        "            output = output.view(batch_size, seq_len, -1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "U3ED7_jf763O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TverskyHeadModel"
      ],
      "metadata": {
        "id": "xKVM6nk_BGzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TverskyHead(nn.Module):\n",
        "    def __init__(self, config, alpha=0.5, beta=0.5, gamma=1.0):\n",
        "        super(TverskyHead, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.transformer = GPT2Model(config)\n",
        "\n",
        "        self.tversky_head = TverskyProjectionLayer(config.n_embd, config.vocab_size, alpha=alpha, beta=beta, gamma=gamma)\n",
        "\n",
        "    def forward(self,input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        transformer_outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        hidden_layers = transformer_outputs.last_hidden_state\n",
        "\n",
        "        lm_logits = self.tversky_head(hidden_layers)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            shift_logits = lm_logits[...,:-1,:].contiguous()\n",
        "            shift_labels = labels[...,1:].contiguous()\n",
        "\n",
        "            loss_f = nn.CrossEntropyLoss()\n",
        "            loss = loss_fc(shift_logits.view(-1, shift_logits.size(-1)),\n",
        "                           shift_labels.view(-1))\n",
        "\n",
        "            return CausalLMOutputWithCrossAttentions(loss=loss, logits=lm_logits, hidden_states=transformer_outputs.hidden_states,\n",
        "                                                     attentions=transformer_outputs.attentions)\n",
        "    def generate(self, input_ids, max_length=50, temperature=1.0, **kwargs):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length - input_ids.size(1)):\n",
        "                outputs = self.forward(input_ids)\n",
        "                next_token_logits = outputs.logits[:,-1,:] / temperature\n",
        "                next_token_id = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                if next_token.item() == self.config.eos_token_id:\n",
        "                    break\n",
        "\n",
        "        return input_ids"
      ],
      "metadata": {
        "id": "bFVSB4hqBLlC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"GPT-2 with Tversky Head Example\")\n",
        "  print(\"=\" * 70)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "  config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "\n",
        "  print(\"Initializing GPT-2 with Tversky head...\")\n",
        "\n",
        "  model = TverskyHead(config, alpha=0.5,beta=0.5,gamma=1.0).to(device)\n",
        "\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  tversky_params = sum(p.numel() for p in model.tversky_head.parameters())\n",
        "  print(f\"Total parameters: {total_params}\")\n",
        "  print(f\"Tversky parameters: {tversky_params}\")"
      ],
      "metadata": {
        "id": "S5A119D-EVJ-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "1e448436c3274497a181fd890a3e47b6",
            "7d0a4b5caf284edf9514257058addf6d",
            "e2d5e508748d4eae9d9ef0c3792cecd2",
            "fe830cae18824d27b90009868041d16f",
            "b493c7969c24472b865590a06e0b8275",
            "85a85903a146467e885d9d35d2be05ac",
            "6f6c6a9923e64120b22a2e5ffb2c6ec4",
            "f428aad3f75a485c9ba5d7984dfbc125",
            "03bf947d16724e25abad8d5ff91149c8",
            "8913943aae6c40a580982d69de80709c",
            "cab4ede138b543aebe46d180a10ffa85",
            "f02ee4e81b7843fbbdee32f1a758c029",
            "8ba4a70e9f7744d1be73fc6942122713",
            "c18326fc6d0b408aa076571be8730782",
            "f8dce00a17c542b78b4a8d1d3f05dcbf",
            "474f11a1c05b4f6b99ee6042cfaa7598",
            "97016b15e051446d8092e8f7efa12988",
            "39f9ef6b70fa40e58d460e462ae6d88a",
            "f45545862acf4d56924d6f9d17b8110e",
            "15f01687d28c44ad96338bed3b45e873",
            "976490aeb1324ed1880f49c7230fb69e",
            "dc0023fdf4cf43e9a802d4250a7ad6d6",
            "3ae8e6a3d4a44ff8a47ec7184c200c91",
            "bad0fa313a94414f92c012ad7685e358",
            "f614d57c779a4235879a363e8e357352",
            "2f81a08b211144ceac3f4902e623a36b",
            "c89c4caaf9a24788b961186a292a84d6",
            "be92bfa7074240f1b2ab2687f32aa175",
            "3d4c150e85384375a6da1372d3428117",
            "79773233ce484defb53056f2b97bc2f8",
            "b495d5611a3e43589dab5a8966e3505f",
            "8615e7beaa4240caa6ba23d3d96698bd",
            "0f7e9429853040d6b61edcfe48e430ed",
            "1f326007577b4bfab90e8843613561f9",
            "90198dd3098b49ffbfb27d2415554b26",
            "127b395b24164d10bc9406341ab1bcb5",
            "6668151623de49b68047680a2669b91e",
            "d7b6d815e3364d7ba8011fcf4c15cbc4",
            "eb52da00a4ed486d83033fba8b6b9389",
            "8ea4b9a29429439581d378cb94596a90",
            "134cf8d81538442b9e2eee97215bab3b",
            "43cfcc944a3f4820b3466df92319df2d",
            "f262a221c21945f7801443cddfb5bf36",
            "b7dc63a5378e446bb5999dc8de838c90",
            "834bf635eb76462db4a1a54c8b7e556a",
            "41f0318faf0b403a9b1a5016ba5d149f",
            "5ad2062e0e47468ea4146975ad8be198",
            "cf92d3dbbc674ec9bcf6c59a8af19705",
            "91ba0adf5d7b42e9b4f1fbd4a036ea86",
            "ba43c6e9ee9744b198146fa96e72ca6f",
            "8654349834214312be1ea0d9cd4e01a5",
            "964682f106524e749d7549eb99c13da9",
            "a118747f41e74097887f54059f030f07",
            "eb27128a29784a208c723ca8e925cb2b",
            "0d78592d0ed64a978dc820fc347bdda5"
          ]
        },
        "id": "MwUIrnuTGGIo",
        "outputId": "d2537180-2d59-4ed8-989a-6a9c9c0fdb99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2 with Tversky Head Example\n",
            "======================================================================\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e448436c3274497a181fd890a3e47b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02ee4e81b7843fbbdee32f1a758c029"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ae8e6a3d4a44ff8a47ec7184c200c91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f326007577b4bfab90e8843613561f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "834bf635eb76462db4a1a54c8b7e556a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing GPT-2 with Tversky head...\n",
            "Total parameters: 202224385\n",
            "Tversky parameters: 77784577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TverskyLinear(nn.Module):\n",
        "    def __init_(self, in_features, out_features, alpha=0.5,beta=0.5, bias=True,fixed_params=True):\n",
        "        super(TverskyLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.prototypes = nn.Parameter(torch.randn(out_features, in_features))\n",
        "\n",
        "        self.features = nn.Parameter(torch.randn(in_features, in_features))\n",
        "\n",
        "        if fixed_params:\n",
        "            self.alpha = nn.register_buffer(torch.tensor(alpha))\n",
        "            self.beta = nn.register_buffer(torch.tensor(beta))\n",
        "            self.gamma = nn.register_buffer(torch.tensor(gamma))\n",
        "        else:\n",
        "            self.alpha = nn.Parameter('alpha',torch.tensor(alpha))\n",
        "            self.beta = nn.Parameter('beta', torch.tensor(beta))\n",
        "            self.gamma = nn.Parameter('gamma', torch.tensor(gamma))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.randn(out_features))\n",
        "        else:\n",
        "            self._register_parameter('bias',None)\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.prototypes)\n",
        "        nn.init.xavier_uniform_(self.features)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def commonality(self, x, prototype):\n",
        "        x_feature_activations = torch.matmul(x, self.features)\n",
        "        x_features = F.relu(x_feature_activations)\n",
        "        prototype_feature_activations = torch.matmul(prototype, self.features)\n",
        "        prototype_features = F.relu(prototype_feature_activations)\n",
        "\n",
        "        common_features = torch.sum(torch.min(x_features,prototype_features))\n",
        "\n",
        "        return common, x_features, prototype_features\n",
        "\n",
        "    def distinct_features(self, features_alpha ,features_beta):\n",
        "        distinctive = torch.sum(F.relu(features_alpha - features_beta),dim=-1)\n",
        "        return distinctive\n",
        "\n",
        "    def tversky_similarity(self, x, prototype):\n",
        "        common, x_features, prototype_features = self.commonality(x,prototype)\n",
        "        distinctive_x = self.distinctive(x_features, prototype_features)\n",
        "        distinctive_prototype = self.distinctive(prototype_features,x_features)\n",
        "\n",
        "        numerator = self.gamma * common\n",
        "        denominator = (self.gamma * common + torch.abs(self.alpha) * distinctive_x + torch.abs(self.beta) * distinctive_prototype + 1e-8)\n",
        "        similarity = numerator / denominator\n",
        "\n",
        "        return similarity\n",
        ""
      ],
      "metadata": {
        "id": "xb8QSezQ5H6D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimize the number of parameters by replacing the QKV layers with Tversky linear layers"
      ],
      "metadata": {
        "id": "PLOxdz6cGyJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TverskyAttention(nn.Module):\n",
        "    def __init__(self,embed_dim,num_heads, dropout=0.1, bias=True,alpha=0.5,beta=0.5,gamma=1.0):\n",
        "        super(TverskyAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_proj = TverskyProjectionLayer(embed_dim, embed_dim, alpha=alpha, beta=beta, gamma=gamma)"
      ],
      "metadata": {
        "id": "UPlu496G2hsd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bHHnSG4C2gZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalFeature:\n",
        "    _instance = None\n",
        "    _feature_matrices = {}\n",
        "\n",
        "    def __new__(cls):\n",
        "        if cls._instance is None:\n",
        "            cls._instance = super(GlobalFeature, cls).__new__(cls)\n",
        "        return cls._instance\n",
        "    def register_feature(self,key, feature_matrix):\n",
        "        self._feature_matrices[key] = feature_matrix\n",
        "\n",
        "    def get_feature(self, key):\n",
        "        return self._feature_matrices.get(key)\n",
        "\n",
        "    def clear(self):\n",
        "        self._feature_matrices.clear()\n",
        "\n",
        "    def has_key(self, key):\n",
        "        return key in self._feature_matrices"
      ],
      "metadata": {
        "id": "fUnn7Wkl9lUr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SharedTverskyLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, feature_key='main', alpha=0.5, beta=0.5, gamma=1.0, bias=True, share_features=True):\n",
        "        super(SharedTverskyLinear, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.feature_key = feature_key\n",
        "        self.share_feature_params = share_features\n",
        "\n",
        "        self.prototypes = nn.Parameter(torch.randn(out_features, in_features))\n",
        "\n",
        "        self.registry = GlobalFeature()\n",
        "        feature_matrix_key = f\"{feature_key}_{in_features}\"\n",
        "\n",
        "        if not self.registry.has_key(feature_matrix_key):\n",
        "            features = nn.Parameter(torch.randn(in_features, in_features))\n",
        "            self.registry.register_feature(feature_matrix_key, features)\n",
        "\n",
        "        self._feature_matrix_key = feature_matrix_key\n",
        "\n",
        "        if share_features:\n",
        "            param_key = f\"tversky_params_{feature_key}\" # Changed key to avoid conflict\n",
        "            if not self.registry.has_key(param_key):\n",
        "                params = {\n",
        "                    'alpha': nn.Parameter(torch.tensor(alpha)),\n",
        "                    'beta': nn.Parameter(torch.tensor(beta)),\n",
        "                    'gamma': nn.Parameter(torch.tensor(gamma))\n",
        "                }\n",
        "                self.registry.register_feature(param_key, params)\n",
        "            self._param_key = param_key\n",
        "            self._alpha = None\n",
        "            self._beta = None\n",
        "            self._gamma = None\n",
        "        else:\n",
        "            self._alpha = nn.Parameter(torch.tensor(alpha))\n",
        "            self._beta = nn.Parameter(torch.tensor(beta))\n",
        "            self._gamma = nn.Parameter(torch.tensor(gamma))\n",
        "            self._param_key = None # Initialize shared parameter key to None\n",
        "\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.randn(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    @property\n",
        "    def features(self):\n",
        "        return self.registry.get_feature(self._feature_matrix_key)\n",
        "\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        if self._param_key:\n",
        "            return self.registry.get_feature(self._param_key)['alpha']\n",
        "        return self._alpha\n",
        "\n",
        "    @alpha.setter\n",
        "    def alpha(self, value):\n",
        "        if not self._param_key:\n",
        "           self._alpha = value\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        if self._param_key:\n",
        "            return self.registry.get_feature(self._param_key)['beta']\n",
        "        return self._beta\n",
        "\n",
        "    @beta.setter\n",
        "    def beta(self, value):\n",
        "        if not self._param_key:\n",
        "            self._beta = value\n",
        "\n",
        "    @property\n",
        "    def gamma(self):\n",
        "        if self._param_key:\n",
        "            return self.registry.get_feature(self._param_key)['gamma']\n",
        "        return self._gamma\n",
        "\n",
        "    @gamma.setter\n",
        "    def gamma(self, value):\n",
        "        if not self._param_key:\n",
        "            self._gamma = value\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.prototypes)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def tversky_similarity_batch(self, x, prototypes):\n",
        "        batch_size = x.size(0)\n",
        "        features = self.features\n",
        "        x_activations = torch.matmul(x, features)\n",
        "        x_features = F.relu(x_activations)\n",
        "\n",
        "        prototypes_activations = torch.matmul(prototypes, features)\n",
        "        prototype_features = F.relu(prototypes_activations)\n",
        "\n",
        "        x_features_expanded = x_features.unsqueeze(1)\n",
        "        prototype_features_expanded = prototype_features.unsqueeze(0)\n",
        "\n",
        "        common_features = torch.sum(torch.min(x_features_expanded, prototype_features_expanded),dim=-1)\n",
        "        distinctive_x = torch.sum(F.relu(x_features_expanded - prototype_features_expanded), dim=-1)\n",
        "        distinctive_prototypes = torch.sum(F.relu(prototype_features_expanded - x_features_expanded), dim=-1)\n",
        "\n",
        "\n",
        "        numerator = self.gamma * common_features\n",
        "        denominator = (self.gamma * common_features + torch.abs(self.alpha) * distinctive_x + torch.abs(self.beta) * distinctive_prototypes + 1e-8)\n",
        "        similarity = numerator / denominator\n",
        "        return similarity\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape[:-1]\n",
        "        x_flattened = x.view(-1, self.in_features)\n",
        "        output = self.tversky_similarity_batch(x_flattened, self.prototypes)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            output += self.bias\n",
        "\n",
        "        output = output.view(*original_shape, self.out_features)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "KBVbl8Z-_IVI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TverskyAttentionShared(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, feature_key='main', dropout=0.1, bias=True, alpha=0.5, beta=0.5, gamma=1.0):\n",
        "        super(TverskyAttentionShared, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_proj = SharedTverskyLinear(embed_dim, embed_dim, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma, bias=bias)\n",
        "        self.k_proj = SharedTverskyLinear(embed_dim, embed_dim, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma,bias=bias)\n",
        "        self.v_proj = SharedTverskyLinear(embed_dim, embed_dim, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma, bias=bias)\n",
        "\n",
        "        self.out_proj = SharedTverskyLinear(embed_dim, embed_dim, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma, bias=bias)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(dropout)\n",
        "        self.resid_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def __split_heads(self, tensor, batch_size):\n",
        "        return tensor.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
        "    def _merge_heads(self, tensor, batch_size):\n",
        "        return tensor.transpose(1,2).contiguous().view(batch_size,-1, self.embed_dim)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, layer_past=None, use_cache=False,output_attentions=False):\n",
        "        batch_size, seq_length = hidden_states.size()[:2]\n",
        "        query = self.q_proj(hidden_states)\n",
        "        key = self.k_proj(hidden_states)\n",
        "        value = self.v_proj(hidden_states)\n",
        "\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past\n",
        "            key = torch.cat([past_key, key], dim=-2)\n",
        "            value = torch.cat([past_value, value],dim=-2)\n",
        "        present = (key, value) if use_cache else None\n",
        "\n",
        "        attn_weights = torch.matmul(query, key.transpose(-1,-2))\n",
        "        attn_weights = attn_weights / (self.head_dim**0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, value)\n",
        "        attn_output = self._merge_heads(attn_output, batch_size)\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "        attn_output = self.resid_dropout(attn_output)\n",
        "\n",
        "        outputs = (attn_output, present)\n",
        "        if output_attentions:\n",
        "            output += (attn_weights,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "YITUPd-9GTH7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SharedTverskyNetwork(nn.Module):\n",
        "    def __init__(self, embed_dim, intermediate_dim, feature_key='main', dropout=0.1, alpha=0.5,beta=0.5, gamma=1.0):\n",
        "        super(SharedTverskyNetwork, self).__init__()\n",
        "        self.layer1 = SharedTverskyLinear(embed_dim,intermediate_dim, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma)\n",
        "        self.layer2 = SharedTverskyLinear(intermediate_dim, embed_dim, feature_key=f\"{feature_key}_intermediate\", alpha=alpha, beta=beta, gamma=gamma)\n",
        "        self.act = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.layer1(hidden_states)\n",
        "        hidden_states = self.act(hidden_states)\n",
        "        hidden_states = self.layer2(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        return hidden_states\n",
        ""
      ],
      "metadata": {
        "id": "9r4op2TKocH8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TverskyTransformerBlock(nn.Module):\n",
        "    def __init__(self, config, feature_key='main', alpha=0.5, beta=0.5, gamma=1.0):\n",
        "        super(TverskyTransformerBlock, self).__init__()\n",
        "        hidden_size = config.n_embd\n",
        "        inner_dim = config.n_inner if config.n_inner is not None else 4 * hidden_size\n",
        "\n",
        "        self.ln_1 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)\n",
        "        self.attn = TverskyAttentionShared(embed_dim=hidden_size, num_heads=config.n_head, feature_key=feature_key, dropout=config.attn_pdrop, alpha=alpha, beta=beta, gamma=gamma)\n",
        "\n",
        "        self.ln_2 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)\n",
        "        self.network = SharedTverskyNetwork(embed_dim=hidden_size, intermediate_dim=inner_dim,feature_key=feature_key, dropout=config.resid_pdrop, alpha=alpha, beta=beta, gamma=gamma)\n",
        "\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, layer_past=None, use_cache=False, output_attentions=False):\n",
        "\n",
        "        residual = hidden_states\n",
        "        attn_outputs = self.attn(hidden_states, attention_mask=attention_mask, layer_past=layer_past, use_cache=use_cache)\n",
        "\n",
        "        attn_output = attn_outputs[0]\n",
        "        outputs = attn_outputs[1:]\n",
        "\n",
        "        hidden_states = residual + attn_output\n",
        "\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.ln_2(hidden_states)\n",
        "        ffn_states = self.network(hidden_states)\n",
        "        hidden_states = residual + ffn_states\n",
        "\n",
        "        if use_cache:\n",
        "            outputs = (hidden_states,) + outputs\n",
        "        else:\n",
        "            outputs = (hidden_states,) + outputs[1:]\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "PL1TrNzZp-mC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2TverskyModel(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT-2 model with globally shared Tversky feature matrices.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, feature_key='main', alpha=0.5, beta=0.5, gamma=1.0):\n",
        "        super(GPT2TverskyModel, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.embed_dim = config.n_embd\n",
        "\n",
        "        # Clear registry for fresh start\n",
        "        GlobalFeature().clear()\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Building GPT-2 with Shared Tversky Layers\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Embeddings (standard)\n",
        "        self.wte = nn.Embedding(config.vocab_size, self.embed_dim)\n",
        "        self.wpe = nn.Embedding(config.n_positions, self.embed_dim)\n",
        "        self.drop = nn.Dropout(config.embd_pdrop)\n",
        "\n",
        "        # Transformer blocks with shared features\n",
        "        self.h = nn.ModuleList([\n",
        "            TverskyTransformerBlock(config, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma)\n",
        "            for _ in range(config.n_layer)\n",
        "        ])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, SharedTverskyLinear):\n",
        "            module.prototypes.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def forward(self,input_ids=None,attention_mask=None,position_ids=None,past_key_values=None,use_cache=None,output_attentions=None,output_hidden_states=None):\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "\n",
        "        batch_size, seq_length = input_ids.size()\n",
        "\n",
        "        if position_ids is None:\n",
        "            past_length = past_key_values[0][0].size(-2) if past_key_values is not None else 0\n",
        "            position_ids = torch.arange(\n",
        "                past_length, seq_length + past_length,\n",
        "                dtype=torch.long, device=input_ids.device\n",
        "            )\n",
        "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "\n",
        "        inputs_embeds = self.wte(input_ids)\n",
        "        position_embeds = self.wpe(position_ids)\n",
        "        hidden_states = inputs_embeds + position_embeds\n",
        "        hidden_states = self.drop(hidden_states)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.view(batch_size, -1)\n",
        "            attention_mask = attention_mask[:, None, None, :]\n",
        "            attention_mask = attention_mask.to(dtype=hidden_states.dtype)\n",
        "            attention_mask = (1.0 - attention_mask) * torch.finfo(hidden_states.dtype).min\n",
        "\n",
        "        presents = () if use_cache else None\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        for i, block in enumerate(self.h):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_past = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            outputs = block(\n",
        "                hidden_states,\n",
        "                attention_mask=attention_mask,\n",
        "                layer_past=layer_past,\n",
        "                use_cache=use_cache,\n",
        "                output_attentions=output_attentions\n",
        "            )\n",
        "\n",
        "            hidden_states = outputs[0]\n",
        "\n",
        "            if use_cache:\n",
        "                presents = presents + (outputs[1],)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (outputs[2 if use_cache else 1],)\n",
        "\n",
        "        hidden_states = self.ln_f(hidden_states)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        return {\n",
        "            'last_hidden_state': hidden_states,\n",
        "            'past_key_values': presents,\n",
        "            'hidden_states': all_hidden_states,\n",
        "            'attentions': all_attentions,\n",
        "        }\n",
        "\n",
        "\n",
        "class GPT2SharedTverskyLMHead(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT-2 LM with shared Tversky layers throughout.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, feature_key='main', alpha=0.5, beta=0.5, gamma=1.0):\n",
        "        super(GPT2SharedTverskyLMHead, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.transformer = GPT2TverskyModel(\n",
        "            config, feature_key=feature_key, alpha=alpha, beta=beta, gamma=gamma\n",
        "        )\n",
        "\n",
        "        # LM head with shared features\n",
        "        self.lm_head = SharedTverskyLinear(\n",
        "            config.n_embd,\n",
        "            config.vocab_size,\n",
        "            feature_key=feature_key,\n",
        "            alpha=alpha, beta=beta, gamma=gamma,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        transformer_outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        hidden_states = transformer_outputs['last_hidden_state']\n",
        "        lm_logits = self.lm_head(hidden_states)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "        return CausalLMOutputWithCrossAttentions(\n",
        "            loss=loss,\n",
        "            logits=lm_logits,\n",
        "            past_key_values=transformer_outputs.get('past_key_values'),\n",
        "            hidden_states=transformer_outputs.get('hidden_states'),\n",
        "            attentions=transformer_outputs.get('attentions'),\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, max_length=50, temperature=1.0, top_k=50):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length - input_ids.size(1)):\n",
        "                outputs = self.forward(input_ids)\n",
        "                next_token_logits = outputs.logits[:, -1, :] / temperature\n",
        "\n",
        "                if top_k > 0:\n",
        "                    indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
        "                    next_token_logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                if next_token.item() == self.config.eos_token_id:\n",
        "                    break\n",
        "\n",
        "        return input_ids"
      ],
      "metadata": {
        "id": "VQ0eBy7xt6wV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count total and trainable parameters.\"\"\"\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    # Count shared feature matrices separately\n",
        "    registry = GlobalFeature()\n",
        "    shared_params = 0\n",
        "    for key, value in registry._feature_matrices.items():\n",
        "        if isinstance(value, nn.Parameter):\n",
        "            shared_params += value.numel()\n",
        "        elif isinstance(value, dict):\n",
        "            for v in value.values():\n",
        "                if isinstance(v, nn.Parameter):\n",
        "                    shared_params += v.numel()\n",
        "\n",
        "    return {\n",
        "        'total': total,\n",
        "        'trainable': trainable,\n",
        "        'shared_features': shared_params\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_models():\n",
        "    \"\"\"Compare standard GPT-2 vs Shared Tversky GPT-2.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MODEL COMPARISON: Standard vs Shared Tversky\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Small config for demonstration\n",
        "    config = GPT2Config(\n",
        "        vocab_size=50257,\n",
        "        n_positions=1024,\n",
        "        n_embd=768,\n",
        "        n_layer=12,\n",
        "        n_head=12,\n",
        "    )\n",
        "\n",
        "    # Standard GPT-2 (reference)\n",
        "    from transformers import GPT2LMHeadModel\n",
        "    standard_model = GPT2LMHeadModel(config)\n",
        "    standard_params = count_parameters(standard_model)\n",
        "\n",
        "    print(f\"\\n1. STANDARD GPT-2\")\n",
        "    print(f\"   Total parameters: {standard_params['total']:,}\")\n",
        "\n",
        "    # Shared Tversky GPT-2\n",
        "    print(f\"\\n2. BUILDING SHARED TVERSKY GPT-2...\")\n",
        "    shared_model = GPT2SharedTverskyLMHead(config, feature_key='gpt2_shared')\n",
        "    shared_params = count_parameters(shared_model)\n",
        "\n",
        "    print(f\"\\n   SHARED TVERSKY GPT-2\")\n",
        "    print(f\"   Total parameters: {shared_params['total']:,}\")\n",
        "    print(f\"   Shared feature parameters: {shared_params['shared_features']:,}\")\n",
        "    print(f\"   Effective parameters: {shared_params['total'] + shared_params['shared_features']:,}\")\n",
        "\n",
        "    # Calculate reduction\n",
        "    reduction = (1 - (shared_params['total'] + shared_params['shared_features']) / standard_params['total']) * 100\n",
        "\n",
        "    print(f\"\\n3. COMPARISON\")\n",
        "    print(f\"   Parameter reduction: {reduction:.1f}%\")\n",
        "    print(f\"   Ratio: {(shared_params['total'] + shared_params['shared_features']) / standard_params['total']:.2f}x\")\n",
        "\n",
        "    # Show shared feature matrix count\n",
        "    registry = GlobalFeature()\n",
        "    print(f\"\\n4. SHARED FEATURE MATRICES\")\n",
        "    print(f\"   Number of unique feature matrices: {len([k for k in registry._feature_matrices.keys() if 'gpt2_shared' in k and not 'params' in k])}\")\n",
        "    for key in registry._feature_matrices.keys():\n",
        "        if 'gpt2_shared' in key and not 'params' in key:\n",
        "            matrix = registry.get_feature(key)\n",
        "            if isinstance(matrix, nn.Parameter):\n",
        "                print(f\"   - {key}: {matrix.shape}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Usage Examples\n",
        "# ============================================================================\n",
        "\n",
        "def example_basic_shared():\n",
        "    \"\"\"Example 1: Basic shared feature usage.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Example 1: Basic Shared Feature Matrix\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Clear registry\n",
        "    GlobalFeature().clear()\n",
        "\n",
        "    # Create multiple layers that share features\n",
        "    layer1 = SharedTverskyLinear(512, 256, feature_key='example')\n",
        "    layer2 = SharedTverskyLinear(512, 128, feature_key='example')\n",
        "    layer3 = SharedTverskyLinear(512, 64, feature_key='example')\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = (\n",
        "        sum(p.numel() for p in layer1.parameters()) +\n",
        "        sum(p.numel() for p in layer2.parameters()) +\n",
        "        sum(p.numel() for p in layer3.parameters())\n",
        "    )\n",
        "\n",
        "    # Count shared features\n",
        "    registry = GlobalFeature()\n",
        "    shared_feature_params = registry.get_feature('example_512').numel()\n",
        "\n",
        "    print(f\"\\nLayer parameters (prototypes + bias): {total_params:,}\")\n",
        "    print(f\"Shared feature matrix parameters: {shared_feature_params:,}\")\n",
        "    print(f\"Total effective parameters: {total_params + shared_feature_params:,}\")\n",
        "\n",
        "    # Compare with non-shared\n",
        "    non_shared_params = 3 * (512 * 512)  # Each layer would have its own feature matrix\n",
        "    print(f\"\\nIf features were NOT shared: {total_params + non_shared_params:,}\")\n",
        "    print(f\"Savings: {non_shared_params - shared_feature_params:,} parameters\")\n",
        "    print(f\"Reduction: {((non_shared_params - shared_feature_params) / (total_params + non_shared_params)) * 100:.1f}%\")\n",
        "\n",
        "\n",
        "def example_full_model():\n",
        "    \"\"\"Example 2: Full model with generation.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Example 2: Full Model with Text Generation\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    config = GPT2Config(\n",
        "        vocab_size=50257,\n",
        "        n_positions=512,\n",
        "        n_embd=384,\n",
        "        n_layer=6,\n",
        "        n_head=6,\n",
        "    )\n",
        "\n",
        "    model = GPT2SharedTverskyLMHead(config, feature_key='demo')\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Test generation\n",
        "    prompt = \"Once upon a time\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"Generating...\")\n",
        "\n",
        "    generated = model.generate(input_ids, max_length=30, temperature=1.0)\n",
        "    generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Generated: '{generated_text}'\")\n",
        "\n",
        "    # Show parameters\n",
        "    params = count_parameters(model)\n",
        "    print(f\"\\nModel parameters: {params['total']:,}\")\n",
        "    print(f\"Shared features: {params['shared_features']:,}\")\n",
        "\n",
        "\n",
        "def example_training():\n",
        "    \"\"\"Example 3: Training loop.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Example 3: Training with Shared Features\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    config = GPT2Config(\n",
        "        vocab_size=50257,\n",
        "        n_positions=128,\n",
        "        n_embd=256,\n",
        "        n_layer=4,\n",
        "        n_head=4,\n",
        "    )\n",
        "\n",
        "    model = GPT2SharedTverskyLMHead(config, feature_key='training')\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Training data\n",
        "    texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"Machine learning is transforming technology.\",\n",
        "        \"Python is a versatile programming language.\",\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    model.train()\n",
        "\n",
        "    print(\"Training for 5 steps...\")\n",
        "    for step in range(5):\n",
        "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Check that shared features receive gradients\n",
        "        registry = GlobalFeature()\n",
        "        feature_matrix = registry.get_feature('training_256')\n",
        "        has_grad = feature_matrix.grad is not None\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Step {step+1}: Loss={loss.item():.4f}, Shared features updated={has_grad}\")\n",
        "\n",
        "    print(\"✓ Training completed!\")\n",
        "    print(\"✓ Shared feature matrices are being updated during training!\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Main\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GPT-2 WITH GLOBALLY SHARED TVERSKY FEATURE MATRICES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    example_basic_shared()\n",
        "    compare_models()\n",
        "    example_full_model()\n",
        "    example_training()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"KEY INSIGHTS\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\"\"\n",
        "    ✓ Feature matrices are shared across ALL Tversky layers\n",
        "    ✓ Each layer has its own prototypes (like weights in nn.Linear)\n",
        "    ✓ Sharing features dramatically reduces parameter count\n",
        "    ✓ This is how the paper achieves 34.8% parameter reduction\n",
        "    ✓ Shared features are trainable and receive gradients\n",
        "    ✓ GlobalFeatureRegistry manages all shared parameters\n",
        "\n",
        "    Paper Reference: arxiv.org/abs/2506.11035\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g5IJJ8jv-Uik",
        "outputId": "571638a2-274e-43b1-f7ab-655f517a67b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "GPT-2 WITH GLOBALLY SHARED TVERSKY FEATURE MATRICES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Example 1: Basic Shared Feature Matrix\n",
            "======================================================================\n",
            "\n",
            "Layer parameters (prototypes + bias): 229,824\n",
            "Shared feature matrix parameters: 262,144\n",
            "Total effective parameters: 491,968\n",
            "\n",
            "If features were NOT shared: 1,016,256\n",
            "Savings: 524,288 parameters\n",
            "Reduction: 51.6%\n",
            "\n",
            "======================================================================\n",
            "MODEL COMPARISON: Standard vs Shared Tversky\n",
            "======================================================================\n",
            "\n",
            "1. STANDARD GPT-2\n",
            "   Total parameters: 124,439,808\n",
            "\n",
            "2. BUILDING SHARED TVERSKY GPT-2...\n",
            "\n",
            "======================================================================\n",
            "Building GPT-2 with Shared Tversky Layers\n",
            "======================================================================\n",
            "======================================================================\n",
            "\n",
            "\n",
            "   SHARED TVERSKY GPT-2\n",
            "   Total parameters: 163,037,184\n",
            "   Shared feature parameters: 10,027,014\n",
            "   Effective parameters: 173,064,198\n",
            "\n",
            "3. COMPARISON\n",
            "   Parameter reduction: -39.1%\n",
            "   Ratio: 1.39x\n",
            "\n",
            "4. SHARED FEATURE MATRICES\n",
            "   Number of unique feature matrices: 2\n",
            "   - gpt2_shared_768: torch.Size([768, 768])\n",
            "   - gpt2_shared_intermediate_3072: torch.Size([3072, 3072])\n",
            "\n",
            "======================================================================\n",
            "Example 2: Full Model with Text Generation\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Building GPT-2 with Shared Tversky Layers\n",
            "======================================================================\n",
            "======================================================================\n",
            "\n",
            "Prompt: 'Once upon a time'\n",
            "Generating...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4131861604.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4131861604.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mexample_basic_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mexample_full_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mexample_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4131861604.py\u001b[0m in \u001b[0;36mexample_full_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4094315363.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, temperature, top_k)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4094315363.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4094315363.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, use_cache, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mlayer_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             outputs = block(\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3632596621.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mffn_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mffn_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1331842513.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4102268186.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0moriginal_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mx_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtversky_similarity_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4102268186.py\u001b[0m in \u001b[0;36mtversky_similarity_batch\u001b[0;34m(self, x, prototypes)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mcommon_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototype_features_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mdistinctive_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features_expanded\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprototype_features_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mdistinctive_prototypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototype_features_expanded\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_features_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}